<!DOCTYPE html>
<html>

<head>
    <title>Welcome</title>
</head>

<body>
    <p>测试页面</p>
    <p>我是英语</p>
    <p>I'm Chinese</p>
    <p>图像匹配[8]
        旨在将两幅图像中具有相同/相似属性的内容或结构进行像素上的识别与对齐。对图像匹配的研究通常分为两类：基于图像特征和基于像素灰度。基于特征的图像匹配方法在旋转、遮挡、光照强弱、尺度大小等因素下具有较强的鲁棒性，是目前主流的图像匹配方法。
    </p>
    <p> 基于特征的图像匹配通常包括以下几步：特征提取和描述、特征匹配、误匹配剔除。特征提取是获取特征点在图像中的位置，具有方向、尺度等信息；特征描述通常是一个向量，描述特征点邻域的像素信息；特征匹配是在向量空间中对两个描述子进行比较，根据距离的远近判定是否为同一特征点[9]；误匹配剔除则是过滤掉初始匹配集中错误匹配，提高匹配的精度。
    <p> 局部特征描述方法有两类：第一类是基于梯度直方图的局部描述方法，使用此类方法的算法有 SIFT、SURF 以及基于这两种算法的许多改进算法；第二类是基于二进制位串的局部描述方法，包括 BRIEF、ORB、BRISK
        等等[10]。</p>
    <p> SIFT（Scale-invariant feature
        transform，尺度不变特征变换）算法是一种基于局部特征的算法，对图像的尺度、旋转、亮度变化不敏感，也对视角变换、仿射变换、噪声等因素也有一定程度的稳定性。但是实时性不高，并且对于边缘光滑目标的特征点提取能力较弱。针对上述的问题，Ke和Sukthankar[11]等人对SIFT算法作出了改进，提出PCA-SIFT（Principle
        Component Analysis SIFT）算法，引入PCA主成分分析方法，减少描述符的维度，提高了时间效率。
        ORB（Oriented FAST and Rotated
        BRIEF）[12]是一种快速特征点提取和描述的算法。该算法分为两部分，分别是特征点提取和特征点描述。特征提取是由FAST[13]算法发展来的，特征点描述是根据BRIEF[14]特征描述算法改进的。ORB特征是将FAST特征点的检测方法与BRIEF特征描述子结合起来，并在它们原来的基础上做了改进与优化。
        随着深度学习的发展，深度神经网络也被应用于特征点的提取。Alahi[15] 等人借鉴视网膜的结构提出了一种FREAK
        描述符，其方法是通过对比视网膜采样图案上的图像强度，以进行快速计算并以低存储成本进行匹配，同时保持对缩放、旋转和噪声的鲁棒性。目前，通过端到端的方式将检测器和描述符联合一起在完整的特征提取流程中也引起了极大的关注。Yi[16]等人提出的LIFT尝试利用端到端CNN
        网络的同时实现关键点检测、姿态估计和特征描述。为了解决多视角几何问题中特征点检测和描述符的训练，Detone [17]
        等人提出自监督SuperPoint的概念，即利用全卷积神经网络框架对全幅图像进行特征点检测和描述，并联合计算像素级别兴趣点定位信息和相关联描述符。
        在对图像局部区域进行特征提取和建立特征描述符后，便可根据两幅图像之间特征描述符的相似性或一致性来建立图像特征点的对应关系，其相似度的度量通常使用欧几里得距离或汉明距离来计算。但初始的匹配含有大量的误匹配对，需要进行误匹配剔除。
    </p>
    随机采样一致性（Random Sample  Consensus，RANSAC）[18]通过特征点计算两幅图像之间的单应性矩阵，然后通过计算重投影误差来判定某个匹配是否正确。但是该方法在图像涉及到非刚性变换时效果并不理想，并且当建立的初始匹配集中内点率很低时，准确性得不到保障。
    Bian [19] 等人提出的GMS算法将运动平滑约束转换为剔除错误匹配的统计量，提出了一种高效的基于网格的得分估计器，使得该算法能够用于实时特征匹配。
</body>

</html>